{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"A100","machine_shape":"hm","authorship_tag":"ABX9TyNXfDOE9gxkzAEfYKBwtojI"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["from pathlib import Path\n","from google.colab import drive\n","\n","# Mount Google Drive\n","drive.mount('/content/drive')\n","\n","# Dataset root\n","ROOT = Path(\"/content/drive/MyDrive/data/classification_dataset\")\n","\n","# Artifact dir\n","SAVE_DIR = ROOT.parent / \"benthic_artifacts\"\n","SAVE_DIR.mkdir(parents=True, exist_ok=True)\n","\n","# File paths for checkpoints/exports\n","CKPT_LAST   = SAVE_DIR / \"convnext_tiny_last.pth\"      # latest checkpoint\n","CKPT_BEST   = SAVE_DIR / \"convnext_tiny_best.pth\"      # best-by-val checkpoint\n","TS_EXPORT   = SAVE_DIR / \"convnext_tiny_scripted.pt\"   # TorchScript export\n","CLASSES_JSON= SAVE_DIR / \"classes.json\"                # class names"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-t64yjyFZpXh","executionInfo":{"status":"ok","timestamp":1760556933233,"user_tz":240,"elapsed":22238,"user":{"displayName":"Dave Xue","userId":"00788427259834126178"}},"outputId":"f07befec-b4d4-4b1a-ad52-ed9d32872127"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["# -------------------- Config & Repro --------------------\n","import torch, random, numpy as np\n","\n","CLASS_NAMES = [\"Scallop\", \"roundfish\", \"crab\", \"whelk\", \"skate\", \"flatfish\", \"Eel\"]\n","CLASS_TO_ID = {c: i for i, c in enumerate(CLASS_NAMES)}\n","IMAGENET_MEAN = [0.485, 0.456, 0.406]\n","IMAGENET_STD  = [0.229, 0.224, 0.225]\n","\n","BATCH = 64\n","EPOCHS = 10\n","EXTRA_EPOCHS = 10\n","LR = 3e-4\n","WD = 1e-2\n","SEED = 12345\n","\n","RESUME = True\n","RESUME_FROM = \"last\"  # \"last\" or \"best\"\n","RESUME_PATH = CKPT_LAST if RESUME_FROM == \"last\" else CKPT_BEST\n","\n","# Colab-friendly DataLoader settings\n","NUM_WORKERS = 3\n","PIN_MEMORY = True\n","PERSISTENT = False\n","PREFETCH = 2\n","\n","# Reproducibility\n","random.seed(SEED)\n","np.random.seed(SEED)\n","torch.manual_seed(SEED)\n","if torch.cuda.is_available():\n","    torch.cuda.manual_seed_all(SEED)"],"metadata":{"id":"oIQUyghmcC9r"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# -------------------- Imports & Utils --------------------\n","from typing import List, Tuple\n","from PIL import Image\n","from sklearn.model_selection import train_test_split\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import transforms\n","from torchvision.models import convnext_tiny, ConvNeXt_Tiny_Weights\n","from torchvision.transforms import InterpolationMode\n","from tqdm import tqdm\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import json\n","\n","# Parse labels.txt and build a list of (image_path, class_id, year) samples.\n","def read_labels(root: str):\n","    root = Path(root)\n","    labels = root / \"labels.txt\"; images = root / \"images\"\n","    samples: List[Tuple[Path, int, str]] = []\n","    with labels.open(\"r\", encoding=\"utf-8\") as f:\n","        for line in f:\n","            filename, label = line.split()\n","            path = images / filename\n","            cid = CLASS_TO_ID[label]\n","            year = filename.split(\"_\", 1)[0]\n","            samples.append((path, cid, year))\n","    return samples\n","\n","# Create a class-stratified 70/15/15 train/val/test split for IID evaluation.\n","def stratified_iid_split(samples, seed=12345):\n","    y = np.array([cid for _, cid, _ in samples])\n","    trainval, test = train_test_split(samples, test_size=0.15, stratify=y, random_state=seed)\n","    y_trainval = np.array([cid for _, cid, _ in trainval])\n","    train, val = train_test_split(trainval, test_size=0.1765, stratify=y_trainval, random_state=seed)\n","    return train, val, test\n","\n","# Minimal Dataset that loads an image (with optional transform) and its class id.\n","class BenthicDataset(Dataset):\n","    def __init__(self, items, transform=None):\n","        self.items = items; self.transform = transform\n","    def __len__(self): return len(self.items)\n","    def __getitem__(self, i):\n","        path, cid, _ = self.items[i]\n","        with Image.open(path) as im: img = im.convert(\"RGB\")\n","        if self.transform: img = self.transform(img)\n","        return img, cid\n","\n","# Build train (augmented) and val/test (deterministic) transforms for 224Ã—224 inputs.\n","def build_transforms():\n","    weights = ConvNeXt_Tiny_Weights.IMAGENET1K_V1\n","    val_tf = weights.transforms(antialias=True)\n","    train_tf = transforms.Compose([\n","        transforms.RandomResizedCrop(224, scale=(0.7, 1.0),\n","                                     interpolation=InterpolationMode.BICUBIC, antialias=True),\n","        transforms.RandomHorizontalFlip(),\n","        transforms.RandomRotation(15, interpolation=InterpolationMode.BILINEAR, fill=0),\n","        transforms.ColorJitter(0.3, 0.3, 0.2, 0.05),\n","        transforms.ToTensor(),\n","        transforms.Normalize(IMAGENET_MEAN, IMAGENET_STD),\n","    ])\n","    return train_tf, val_tf\n","\n","# Evaluate top-1 accuracy over a DataLoader with no grad in eval mode.\n","@torch.no_grad()\n","def evaluate(model, loader, device):\n","    model.eval()\n","    correct = total = 0\n","    for xb, yb in loader:\n","        xb, yb = xb.to(device), yb.to(device)\n","        pred = model(xb).argmax(1)\n","        correct += (pred == yb).sum().item()\n","        total += yb.size(0)\n","    return correct / total if total else 0.0"],"metadata":{"id":"wwVMYbXvc_T8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# -------------------- Checkpoint / Resume Helpers --------------------\n","\n","# Save a full training snapshot (model + epoch/metrics + optimizer/scaler + hparams).\n","def save_checkpoint(path: Path, model: nn.Module, epoch: int, val_acc: float, *,\n","                    optimizer=None, scaler=None, extra: dict = None):\n","    payload = {\n","        \"epoch\": int(epoch),\n","        \"val_acc\": float(val_acc),\n","        \"state_dict\": model.state_dict(),\n","        \"arch\": \"convnext_tiny\",\n","        \"num_classes\": len(CLASS_NAMES),\n","        \"class_names\": CLASS_NAMES,\n","        \"hparams\": {\"lr\": LR, \"weight_decay\": WD, \"batch\": BATCH, \"label_smoothing\": 0.1},\n","        \"optimizer\": optimizer.state_dict() if optimizer is not None else None,\n","        \"scaler\": scaler.state_dict() if scaler is not None else None,\n","    }\n","    if extra: payload.update(extra)\n","    path.parent.mkdir(parents=True, exist_ok=True)\n","    torch.save(payload, path)\n","\n","# Export a portable TorchScript model for inference without the Python class.\n","def export_torchscript(model: nn.Module, path: Path, device: torch.device):\n","    model_cpu = model.to(\"cpu\").eval()\n","    scripted = torch.jit.trace(model_cpu, torch.randn(1, 3, 224, 224))\n","    scripted.save(str(path))\n","    model.to(device)\n","\n","# Rebuild model/optimizer/scaler from a checkpoint and return resume state.\n","def resume_from_checkpoint(ckpt_path: Path, device, device_type):\n","    ckpt = torch.load(ckpt_path, map_location=\"cpu\")\n","    model = convnext_tiny(weights=None)\n","    model.classifier[-1] = nn.Linear(model.classifier[-1].in_features, ckpt[\"num_classes\"])\n","    model.load_state_dict(ckpt[\"state_dict\"]); model.to(device)\n","\n","    optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=WD)\n","    if ckpt.get(\"optimizer\") is not None:\n","        optimizer.load_state_dict(ckpt[\"optimizer\"])\n","\n","    scaler = torch.amp.GradScaler(device_type) if device_type == \"cuda\" else None\n","    if scaler is not None and ckpt.get(\"scaler\") is not None:\n","        scaler.load_state_dict(ckpt[\"scaler\"])\n","\n","    start_epoch = int(ckpt.get(\"epoch\", 0)) + 1\n","    best_val = float(ckpt.get(\"val_acc\", 0.0))\n","    return model, optimizer, scaler, start_epoch, best_val"],"metadata":{"id":"mq3tILXGds8A"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# -------------------- Build loaders --------------------\n","samples = read_labels(ROOT)\n","train_items, val_items, test_items = stratified_iid_split(samples, seed=SEED)\n","train_tf, val_tf = build_transforms()\n","\n","train_loader = DataLoader(\n","    BenthicDataset(train_items, transform=train_tf),\n","    batch_size=BATCH, shuffle=True,\n","    num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY,\n","    persistent_workers=PERSISTENT, prefetch_factor=PREFETCH,\n","    drop_last=True)\n","\n","val_loader = DataLoader(\n","    BenthicDataset(val_items, transform=val_tf),\n","    batch_size=BATCH, shuffle=False,\n","    num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY,\n","    persistent_workers=PERSISTENT, prefetch_factor=PREFETCH,\n","    drop_last=False)\n","\n","test_loader = DataLoader(\n","    BenthicDataset(test_items, transform=val_tf),\n","    batch_size=BATCH, shuffle=False,\n","    num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY,\n","    persistent_workers=PERSISTENT, prefetch_factor=PREFETCH,\n","    drop_last=False)"],"metadata":{"id":"5LPORwp-fdzb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# -------------------- Model + AMP (Init or Resume) --------------------\n","\n","# Select device (GPU if available) and set up AMP (automatic mixed precision)\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","device_type = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","autocast_cm = torch.amp.autocast(device_type=device_type, enabled=(device_type == \"cuda\"))\n","scaler = torch.amp.GradScaler(device_type) if device_type == \"cuda\" else None\n","\n","# Persist class names for inference scripts (map logits -> labels without importing this notebook)\n","with CLASSES_JSON.open(\"w\", encoding=\"utf-8\") as f:\n","    json.dump(CLASS_NAMES, f, ensure_ascii=False, indent=2)\n","\n","# Resume path: load a saved checkpoint if requested and available\n","if RESUME and RESUME_PATH.exists():\n","    model, opt, scaler, start_epoch, best_val = resume_from_checkpoint(RESUME_PATH, device, device_type)\n","    print(f\"Resumed from {RESUME_PATH} at epoch {start_epoch} (best val_acc={best_val:.3f})\")\n","    end_epoch = (start_epoch - 1) + EXTRA_EPOCHS\n","\n","# Fresh start: initialize from ImageNet weights and create optimizer\n","else:\n","    model = convnext_tiny(weights=ConvNeXt_Tiny_Weights.IMAGENET1K_V1)\n","    model.classifier[-1] = nn.Linear(model.classifier[-1].in_features, len(CLASS_NAMES))\n","    model.to(device)\n","    opt = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=WD)\n","    start_epoch, best_val = 1, 0.0\n","    end_epoch = EPOCHS"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9VlWiE6Bf0pj","executionInfo":{"status":"ok","timestamp":1760557260500,"user_tz":240,"elapsed":10993,"user":{"displayName":"Dave Xue","userId":"00788427259834126178"}},"outputId":"beff6b03-f213-437d-8a9f-81b57032a889"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Resumed from /content/drive/MyDrive/data/benthic_artifacts/convnext_tiny_last.pth at epoch 11 (best val_acc=0.914)\n"]}]},{"cell_type":"code","source":["# -------------------- Training Loop --------------------\n","for epoch in range(start_epoch, end_epoch + 1):\n","    model.train()\n","    running = 0.0; n_seen = 0\n","    for xb, yb in tqdm(train_loader, desc=f\"Epoch {epoch}/{end_epoch}\"):\n","        xb, yb = xb.to(device), yb.to(device)\n","        opt.zero_grad(set_to_none=True)\n","        with autocast_cm:\n","            logits = model(xb)\n","            loss = F.cross_entropy(logits, yb, label_smoothing=0.1)\n","        if scaler is not None:\n","            scaler.scale(loss).backward()\n","            scaler.step(opt)\n","            scaler.update()\n","        else:\n","            loss.backward()\n","            opt.step()\n","        running += loss.item() * xb.size(0); n_seen += xb.size(0)\n","\n","    train_loss = running / max(1, n_seen)\n","    val_acc = evaluate(model, val_loader, device)\n","    print(f\"loss={train_loss:.4f}  val_acc={val_acc:.3f}\")\n","\n","    # save last each epoch\n","    save_checkpoint(CKPT_LAST, model, epoch, val_acc, optimizer=opt, scaler=scaler, extra={\"split\": \"iid\"})\n","\n","    # save best and export torchscript\n","    if val_acc > best_val:\n","        best_val = val_acc\n","        save_checkpoint(CKPT_BEST, model, epoch, val_acc, optimizer=opt, scaler=scaler, extra={\"split\": \"iid\"})\n","        export_torchscript(model, TS_EXPORT, device)\n","        print(f\"  â†³ saved BEST: {CKPT_BEST}\")\n","        print(f\"  â†³ exported TorchScript: {TS_EXPORT}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3GSjT-tkaq2u","executionInfo":{"status":"ok","timestamp":1760559272365,"user_tz":240,"elapsed":2003092,"user":{"displayName":"Dave Xue","userId":"00788427259834126178"}},"outputId":"3da24fb0-a6fe-4172-fbd8-8598ce14c48b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Epoch 11/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 114/114 [18:43<00:00,  9.86s/it]\n"]},{"output_type":"stream","name":"stdout","text":["loss=0.5177  val_acc=0.904\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 12/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 114/114 [01:04<00:00,  1.76it/s]\n"]},{"output_type":"stream","name":"stdout","text":["loss=0.5059  val_acc=0.921\n","  â†³ saved BEST: /content/drive/MyDrive/data/benthic_artifacts/convnext_tiny_best.pth\n","  â†³ exported TorchScript: /content/drive/MyDrive/data/benthic_artifacts/convnext_tiny_scripted.pt\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 13/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 114/114 [00:58<00:00,  1.93it/s]\n"]},{"output_type":"stream","name":"stdout","text":["loss=0.4966  val_acc=0.905\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 14/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 114/114 [00:56<00:00,  2.01it/s]\n"]},{"output_type":"stream","name":"stdout","text":["loss=0.5211  val_acc=0.906\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 15/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 114/114 [00:56<00:00,  2.01it/s]\n"]},{"output_type":"stream","name":"stdout","text":["loss=0.5145  val_acc=0.904\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 16/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 114/114 [00:56<00:00,  2.02it/s]\n"]},{"output_type":"stream","name":"stdout","text":["loss=0.5259  val_acc=0.906\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 17/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 114/114 [00:55<00:00,  2.04it/s]\n"]},{"output_type":"stream","name":"stdout","text":["loss=0.5169  val_acc=0.905\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 18/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 114/114 [00:55<00:00,  2.04it/s]\n"]},{"output_type":"stream","name":"stdout","text":["loss=0.5048  val_acc=0.909\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 19/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 114/114 [00:55<00:00,  2.05it/s]\n"]},{"output_type":"stream","name":"stdout","text":["loss=0.5014  val_acc=0.908\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 20/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 114/114 [00:55<00:00,  2.04it/s]\n"]},{"output_type":"stream","name":"stdout","text":["loss=0.5085  val_acc=0.906\n"]}]},{"cell_type":"code","source":["# --- Load best checkpoint and eval on test_loader ---\n","import torch, torch.nn as nn\n","from torchvision.models import convnext_tiny\n","\n","ckpt_path = \"/content/drive/MyDrive/data/benthic_artifacts/convnext_tiny_best.pth\"\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","ckpt = torch.load(ckpt_path, map_location=\"cpu\")\n","model = convnext_tiny(weights=None)\n","model.classifier[-1] = nn.Linear(model.classifier[-1].in_features, ckpt[\"num_classes\"])\n","model.load_state_dict(ckpt[\"state_dict\"])\n","model.to(device).eval()\n","\n","# assumes you still have `evaluate()` and `test_loader` defined\n","test_acc = evaluate(model, test_loader, device)\n","print(f\"Test acc: {test_acc:.3f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MHDuoGXnip-D","executionInfo":{"status":"ok","timestamp":1760559810898,"user_tz":240,"elapsed":6775,"user":{"displayName":"Dave Xue","userId":"00788427259834126178"}},"outputId":"d141dcce-72a6-4945-8637-92249393b23a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Test acc: 0.932\n"]}]},{"cell_type":"code","source":["# -------------------- Final test --------------------\n","test_acc = evaluate(model, test_loader, device)\n","print(f\"Test acc: {test_acc:.3f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OOPX6q1jg7P9","executionInfo":{"status":"ok","timestamp":1760559558152,"user_tz":240,"elapsed":268489,"user":{"displayName":"Dave Xue","userId":"00788427259834126178"}},"outputId":"5bbefbe2-a254-454f-e2e7-4fed05d17502"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Test acc: 0.915\n"]}]}]}